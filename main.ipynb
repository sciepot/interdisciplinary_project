{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MxnjXPG7HUyu"
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmtxCqx6HZhs",
        "outputId": "b6327dd5-c9b9-4294-9db5-a2bf44449eb0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPOYZ98iIHVd",
        "outputId": "139d43b7-5675-468c-9e62-b060c7338182"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42UbiGVwHUyw"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from transformers import AutoModel, AutoTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUF94-LvHUyx",
        "outputId": "35f76dc6-159b-4c21-e377-e1b4f08e0141"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQTFDme2HUyy",
        "outputId": "a5a88ed7-2252-49c9-c7a8-1d6a5c3c5a41"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wdEId5gVHUyy"
      },
      "source": [
        "Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgyhXuW7ZQsH"
      },
      "outputs": [],
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, filepath, num_classes, train_size, valid_size, test_size, device, batch_size, chunksize=10000):\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.train_size = train_size\n",
        "        self.valid_size = valid_size\n",
        "        self.test_size = test_size\n",
        "        self.mode = 'train'\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.dataloader = pd.read_csv(filepath, usecols=[5,8], iterator=True, chunksize=chunksize)\n",
        "\n",
        "        model_name = 'distilbert-base-cased'\n",
        "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        raw_data = None\n",
        "\n",
        "        for index, chunk in enumerate(self.dataloader):\n",
        "            if index == 0:\n",
        "                raw_data = chunk\n",
        "            else:\n",
        "                raw_data = pd.concat([raw_data, chunk], axis=0)\n",
        "        \n",
        "        self.filtered = []\n",
        "        sizes = []\n",
        "        for i in range(num_classes):\n",
        "          self.filtered.append(raw_data[raw_data['stars'] == i + 1])\n",
        "          sizes.append(self.filtered[i].shape[0])\n",
        "        size = min(sizes)\n",
        "        self.data = self.filtered[0][:size]\n",
        "        for i in range(1, num_classes):\n",
        "          self.data = pd.concat([self.data, self.filtered[i][:size]], axis=0)\n",
        "\n",
        "        self.data = self.data.sample(frac=1)\n",
        "        self.data_size = self.data.shape[0]\n",
        "        self.offset = valid_size + test_size\n",
        "\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        self.mode = mode\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.ptr_idx = 0\n",
        "        self.end_idx = 0\n",
        "        if self.mode == 'train':\n",
        "            if self.offset + self.train_size >= self.data_size:\n",
        "                self.offset = self.valid_size + self.test_size\n",
        "            self.ptr_idx = self.offset\n",
        "            self.end_idx = self.offset + self.train_size\n",
        "        elif self.mode == 'valid':\n",
        "            self.ptr_idx = 0\n",
        "            self.end_idx = self.valid_size\n",
        "        elif self.mode == 'test':\n",
        "            self.ptr_idx = self.valid_size\n",
        "            self.end_idx = self.valid_size + self.test_size\n",
        "        else: raise Exception(\"Incorrect mode chosen!!!\")\n",
        "        return self\n",
        "\n",
        "    def __next__(self): \n",
        "        if self.ptr_idx + self.batch_size < self.end_idx:\n",
        "            batch = self.data[self.ptr_idx : self.ptr_idx + self.batch_size]\n",
        "            self.ptr_idx += self.batch_size\n",
        "            return self.get_batch(batch)\n",
        "        else:\n",
        "            raise StopIteration\n",
        "\n",
        "    def get_batch(self, batch):\n",
        "        targets = [] # b\n",
        "        emb_holder = [] # b x s x w x e\n",
        "        mask_holder = [] # b x s x w\n",
        "        for _, row in batch.iterrows():\n",
        "            targets.append(int(row['stars']) - 1)\n",
        "            embedding, mask = self.get_document(row['text'])\n",
        "            emb_holder.append(embedding)\n",
        "            mask_holder.append(mask)\n",
        "        return self.adjust_batch(emb_holder, mask_holder), torch.tensor(targets, dtype=torch.long, device=self.device)\n",
        " \n",
        "    def get_document(self, text):\n",
        "        with torch.no_grad():                 \n",
        "            sentences = sent_tokenize(text)\n",
        "            model_inputs = self.tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
        "            embedding = self.model(model_inputs.input_ids, attention_mask=model_inputs.attention_mask).last_hidden_state.to(self.device)\n",
        "            return (embedding, model_inputs.attention_mask)\n",
        "    \n",
        "    def adjust_batch(self, emb_holder, mask_holder):\n",
        "        s_size = emb_holder[0].size(dim=0)\n",
        "        w_size = emb_holder[0].size(dim=1)\n",
        "        e_size = emb_holder[0].size(dim=2)\n",
        "\n",
        "        embeddings = None\n",
        "        masks = None\n",
        "        sen_masks = None\n",
        "        for i in range(1, len(emb_holder)):\n",
        "            if s_size < emb_holder[i].size(dim=0):\n",
        "                s_size = emb_holder[i].size(dim=0)\n",
        "            if w_size < emb_holder[i].size(dim=1):\n",
        "                w_size = emb_holder[i].size(dim=1)\n",
        "\n",
        "        init = True\n",
        "        for emb, mask in zip(emb_holder, mask_holder):\n",
        "            sen_mask = torch.cat((torch.ones(emb.size(dim=0), device=self.device),\n",
        "                                  torch.zeros(s_size - emb.size(dim=0), device=self.device)), dim=0).unsqueeze(dim=0)\n",
        "\n",
        "            emb = torch.cat((emb, torch.zeros(emb.size(dim=0), w_size - emb.size(dim=1), e_size, device=self.device)), dim=1)\n",
        "            emb = torch.cat((emb, torch.zeros(s_size - emb.size(dim=0), w_size, e_size, device=self.device)), dim=0).unsqueeze(dim=0)\n",
        "\n",
        "            mask = torch.cat((mask, torch.zeros(mask.size(dim=0), w_size - mask.size(dim=1), device=self.device)), dim=1)\n",
        "            mask = torch.cat((mask, torch.zeros(s_size - mask.size(dim=0), w_size, device=self.device)), dim=0).unsqueeze(dim=0)\n",
        "            if init:\n",
        "                embeddings = emb\n",
        "                masks = mask\n",
        "                sen_masks = sen_mask\n",
        "                init = False\n",
        "            else:\n",
        "                embeddings = torch.cat((embeddings, emb), dim=0)\n",
        "                masks = torch.cat((masks, mask), dim=0)\n",
        "                sen_masks = torch.cat((sen_masks, sen_mask), dim=0)\n",
        "        return (embeddings, masks, sen_masks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHT-AG_QHUyz",
        "outputId": "199b34a1-42d0-4e05-c35f-802aa7378cfc"
      },
      "outputs": [],
      "source": [
        "FILEPATH = \"/content/drive/MyDrive/Colab/yelp_academic_dataset_review.csv\"\n",
        "NUM_CLASSES = 5\n",
        "CHUNK_SIZE = 10000\n",
        "TRAIN_SIZE= 10000\n",
        "VALID_SIZE = 2000\n",
        "TEST_SIZE = 2000\n",
        "BATCH_SIZE = 4\n",
        "dataloader = DataLoader(FILEPATH, NUM_CLASSES, TRAIN_SIZE, VALID_SIZE, TEST_SIZE, device, BATCH_SIZE, CHUNK_SIZE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbDeK4NHUyz"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpCQkRAFHUyz"
      },
      "outputs": [],
      "source": [
        "class HCAN(nn.Module):\n",
        "    def __init__(self, num_classes, dim, heads, device, word_kernel, sen_kernel, dtype=torch.float32):\n",
        "        super(HCAN, self).__init__()\n",
        "        padding_word = word_kernel - 2\n",
        "        padding_sen = sen_kernel - 2\n",
        "        self.Qa = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim,  padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )        \n",
        "        self.Ka = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.Va = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.Qb = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )        \n",
        "        self.Kb = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.Vb = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.Kt = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.Vt = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_word, kernel_size=word_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.multihead_word  = nn.MultiheadAttention(embed_dim=dim, num_heads=heads,\n",
        "                                                batch_first=True, device=device, dtype=dtype)\n",
        "        \n",
        "        self.T_word = nn.Parameter(torch.randn(1, 1, dim, device=device),  requires_grad=True)\n",
        "\n",
        "        self.QaS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim,  padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )        \n",
        "        self.KaS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.VaS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.QbS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )        \n",
        "        self.KbS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.VbS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.KtS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.SELU()\n",
        "        )\n",
        "        self.VtS = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=dim, out_channels=dim, padding=padding_sen, kernel_size=sen_kernel,\n",
        "            device=device, dtype=dtype),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.multihead_sen  = nn.MultiheadAttention(embed_dim=dim, num_heads=heads,\n",
        "                                                batch_first=True, device=device, dtype=dtype)\n",
        "        \n",
        "        self.T_sen = nn.Parameter(torch.randn(1, 1, dim, device=device), requires_grad=True)\n",
        "        \n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(dim, 100, device=device),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(100, 20, device=device),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(20, num_classes, device=device),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input): # E b x s x l x d\n",
        "        sizes = input[0].size()\n",
        "\n",
        "        E = input[0].view(sizes[0] * sizes[1], sizes[2], sizes[3])\n",
        "        E = E.transpose(2, 1)\n",
        "\n",
        "        M = input[1].view(sizes[0] * sizes[1], sizes[2])\n",
        "        M = M.unsqueeze(dim=-1)\n",
        "\n",
        "        S = input[2].unsqueeze(dim=-1)\n",
        "\n",
        "        Qa = torch.mul(M, self.Qa(E).transpose(1, 2))\n",
        "        Ka = torch.mul(M, self.Ka(E).transpose(1, 2))\n",
        "        Va = torch.mul(M, self.Va(E).transpose(1, 2))\n",
        "        Qb = torch.mul(M, self.Qb(E).transpose(1, 2))\n",
        "        Kb = torch.mul(M, self.Kb(E).transpose(1, 2))\n",
        "        Vb = torch.mul(M, self.Vb(E).transpose(1, 2))\n",
        "        A = torch.mul(M, self.multihead_word(Qa, Ka, Va)[0])\n",
        "        B = torch.mul(M, self.multihead_word(Qb, Kb, Vb)[0])\n",
        "        Eout = torch.mul(A, B).transpose(2, 1)\n",
        "        Kt = torch.mul(M, self.Kt(Eout).transpose(1, 2))\n",
        "        Vt = torch.mul(M, self.Vt(Eout).transpose(1, 2))\n",
        "\n",
        "        D = self.multihead_word(self.T_word.expand(Kt.size(dim=0), 1, Kt.size(dim=2)), Kt, Vt)[0].squeeze(dim=1)\n",
        "        \n",
        "        D = D.view(sizes[0], sizes[1], sizes[3])\n",
        "        D = torch.mul(S, D)\n",
        "        D = D.transpose(2, 1)\n",
        "        QaS = torch.mul(S, self.QaS(D).transpose(1, 2))\n",
        "        KaS = torch.mul(S, self.KaS(D).transpose(1, 2))\n",
        "        VaS = torch.mul(S, self.VaS(D).transpose(1, 2))\n",
        "        QbS = torch.mul(S, self.QbS(D).transpose(1, 2))\n",
        "        KbS = torch.mul(S, self.KbS(D).transpose(1, 2))\n",
        "        VbS = torch.mul(S, self.VbS(D).transpose(1, 2))\n",
        "        AS = torch.mul(S, self.multihead_sen(QaS, KaS, VaS)[0])\n",
        "        BS = torch.mul(S, self.multihead_sen(QbS, KbS, VbS)[0])\n",
        "        Dout = torch.mul(AS, BS).transpose(1, 2)\n",
        "        KtS = torch.mul(S, self.KtS(Dout).transpose(1, 2))\n",
        "        VtS = torch.mul(S, self.VtS(Dout).transpose(1, 2))\n",
        "\n",
        "        doc = self.multihead_sen(self.T_sen.expand(KtS.size(dim=0), 1, KtS.size(dim=2)), KtS, VtS)[0] # b x 1 x e\n",
        "\n",
        "        return self.softmax(self.classifier(self.softmax(doc))).squeeze(dim=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6MSuSmJ-HUy0"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G3sY63wHUy0"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_SIZE = 768\n",
        "NUM_HEADS = 8\n",
        "WINDOW_SIZE = 3\n",
        "SEN_WINDOW_SIZE = 3\n",
        "hcan = HCAN(NUM_CLASSES, EMBEDDING_SIZE, NUM_HEADS, device, WINDOW_SIZE, SEN_WINDOW_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YUM3k3bHUy0",
        "outputId": "bf53a61e-b642-439b-cf2a-e8deab247374"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "hcan.apply(initialize_weights)\n",
        "hcan.load_state_dict(torch.load('/content/drive/MyDrive/my-model-6.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcdjE-WBCgaG"
      },
      "outputs": [],
      "source": [
        "def percentage(model, data):\n",
        "  guessed = [0 for i in range(5)]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    inputs = data.get_examples(20)\n",
        "    for star, input in enumerate(inputs):\n",
        "      for x in input:\n",
        "        if star == torch.argmax(model.forward(x)).item():\n",
        "          guessed[star] += 1\n",
        "  print(f\"Accuracy: {sum(guessed)}%\")\n",
        "  for i in range(5):\n",
        "    print(f\"{i} star: {round(guessed[i]/len(inputs[i])*100)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja3lHzlHHUy1"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    dataloader.set_mode('train')\n",
        "    size = dataloader.train_size/dataloader.batch_size\n",
        "    count = 0\n",
        "    blyat = 0\n",
        "    step = math.floor(size/100)\n",
        "    prev = 0\n",
        "    for input, target in dataloader:\n",
        "        if count >= step:\n",
        "          msg = f\"Train processed: {round((blyat*count)/size*100)}%\"\n",
        "          if blyat != 0:\n",
        "            print(\"\\b\"*prev)\n",
        "          prev = len(msg) + 2\n",
        "          blyat += 1\n",
        "          print(msg)\n",
        "          count = 0\n",
        "        count += 1\n",
        "        optimizer.zero_grad()\n",
        "        predicted = model.forward(input)\n",
        "        loss = criterion(predicted, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(\"\\b\"*prev)\n",
        "        \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BhiTjcvHUy1"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    dataloader.set_mode('valid')\n",
        "    size = dataloader.valid_size/dataloader.batch_size\n",
        "    count = 0\n",
        "    blyat = 0\n",
        "    step = math.floor(size/100)\n",
        "    prev = 0\n",
        "    with torch.no_grad():\n",
        "        for input, target in dataloader:\n",
        "            if count >= step:\n",
        "              msg = f\"Validation processed: {round((blyat*count)/size*100)}%\"\n",
        "              if blyat != 0:\n",
        "                print(\"\\b\"*prev)\n",
        "              prev = len(msg) + 2\n",
        "              blyat += 1\n",
        "              print(msg)\n",
        "              count = 0\n",
        "            count += 1\n",
        "            predicted = model.forward(input)\n",
        "            loss = criterion(predicted, target)\n",
        "            epoch_loss += loss.item()\n",
        "    print(\"\\b\"*prev)\n",
        "        \n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygWalm8sHUy1"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncn-ghfBHUy1",
        "outputId": "a28288ec-3040-45b2-ad83-d0cd3f689b02"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.01\n",
        "optimizer = torch.optim.SGD(hcan.parameters(), lr = LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(hcan, dataloader, optimizer, criterion)\n",
        "    valid_loss = evaluate(hcan, dataloader, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    torch.save(hcan.state_dict(), '/content/drive/MyDrive/my-model-{}.pt'.format(epoch + 1))\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "    #percentage(hcan, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def percentage_accuracy(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    size = dataloader.test_size/dataloader.batch_size\n",
        "    count = 0\n",
        "    blyat = 0\n",
        "    step = math.floor(size/100)\n",
        "    prev = 0\n",
        "\n",
        "    CLASS_COUNTS = [0 for i in range(dataloader.num_classes)]\n",
        "    LABEL_COUNTS = [0 for i in range(dataloader.num_classes)]\n",
        "    COUNTS = 0\n",
        "    dataloader.set_mode('test')\n",
        "    with torch.no_grad():\n",
        "        for input, target in dataloader:\n",
        "              if count >= step:\n",
        "                  msg = f\"Test processed: {round((blyat*count)/size*100)}%\"\n",
        "                  if blyat != 0:\n",
        "                      print(\"\\b\"*prev)\n",
        "                  prev = len(msg) + 2\n",
        "                  blyat += 1\n",
        "                  print(msg)\n",
        "                  count = 0\n",
        "              count += 1\n",
        "              predicted = model.forward(input)\n",
        "              labels = torch.argmax(predicted, dim=1)\n",
        "              COUNTS += torch.sum(torch.eq(target, labels)).item()\n",
        "\n",
        "              for value in range(dataloader.num_classes):\n",
        "                  matched = torch.eq(target, value)\n",
        "                  CLASS_COUNTS[value] += torch.sum(matched).item()\n",
        "                  LABEL_COUNTS[value] += torch.sum(torch.eq(matched, torch.eq(labels, value))).item()\n",
        "    print(\"\\b\"*prev)\n",
        "    print(f\"Accuracy: {COUNTS/dataloader.test_size*100:.2f}%\")\n",
        "    for i in range(dataloader.num_classes):\n",
        "        print(f\"{i + 1} class accuracy:{LABEL_COUNTS[i]/CLASS_COUNTS[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percentage_accuracy(hcan, dataloader,)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
